{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import h5py\n",
    "\n",
    "train_file_name = '../data/draper/raw/VDISC_train.hdf5'\n",
    "train_file = h5py.File(train_file_name)\n",
    "\n",
    "import clang.cindex\n",
    "import clang.enumerations\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "# set the config\n",
    "clang.cindex.Config.set_library_path(\"/usr/lib/x86_64-linux-gnu\")\n",
    "clang.cindex.Config.set_library_file('/usr/lib/x86_64-linux-gnu/libclang-6.0.so.1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "class Tokenizer:\n",
    "    # creates the object, does the inital parse\n",
    "    def __init__(self, path, tokenizer_type='original'):\n",
    "        self.index = clang.cindex.Index.create()\n",
    "        self.tu = self.index.parse(path)\n",
    "        self.path = self.extract_path(path)\n",
    "        self.symbol_table = {}\n",
    "        self.symbol_count = 1\n",
    "        self.tokenizer_type = tokenizer_type\n",
    "\n",
    "    # To output for split_functions, must have same path up to last two folders\n",
    "    def extract_path(self, path):\n",
    "        return \"\".join(path.split(\"/\")[:-2])\n",
    "\n",
    "    \n",
    "    def full_tokenize_cursor(self, cursor):\n",
    "        tokens = cursor.get_tokens()\n",
    "        result = []\n",
    "        for token in tokens:\n",
    "            if token.kind.name == \"COMMENT\":\n",
    "                continue\n",
    "            if token.kind.name == \"LITERAL\":\n",
    "                result += self.process_literal(token)\n",
    "                continue\n",
    "            if token.kind.name == \"IDENTIFIER\":\n",
    "                result += [\"ID\"]\n",
    "                continue\n",
    "            result += [token.spelling]\n",
    "        return result\n",
    "\n",
    "    def full_tokenize(self):\n",
    "        cursor = self.tu.cursor\n",
    "        return self.full_tokenize_cursor(cursor)\n",
    "\n",
    "    def process_literal(self, literal):\n",
    "        cursor_kind = clang.cindex.CursorKind\n",
    "        kind = literal.cursor.kind\n",
    "        if kind == cursor_kind.INTEGER_LITERAL:\n",
    "            return literal.spelling\n",
    "        if kind == cursor_kind.FLOATING_LITERAL:\n",
    "            return literal.spelling\n",
    "        if kind == cursor_kind.IMAGINARY_LITERAL:\n",
    "            return [\"NUM\"]       \n",
    "        if kind == cursor_kind.STRING_LITERAL:\n",
    "            return [\"STRING\"]\n",
    "        sp = literal.spelling\n",
    "        if re.match('[0-9]+', sp) is not None:\n",
    "            return sp\n",
    "        return [\"LITERAL\"]\n",
    "\n",
    "    def split_functions(self, method_only):\n",
    "        results = []\n",
    "        cursor_kind = clang.cindex.CursorKind\n",
    "        cursor = self.tu.cursor\n",
    "        for c in cursor.get_children():\n",
    "            filename = c.location.file.name if c.location.file != None else \"NONE\"\n",
    "            extracted_path = self.extract_path(filename)\n",
    "\n",
    "            if (c.kind == cursor_kind.CXX_METHOD or (method_only == False and c.kind == cursor_kind.FUNCTION_DECL)) and extracted_path == self.path:\n",
    "                name = c.spelling\n",
    "                tokens = self.full_tokenize_cursor(c)\n",
    "                filename = filename.split(\"/\")[-1]\n",
    "                results += [tokens]\n",
    "\n",
    "        return results\n",
    "    \n",
    "\n",
    "def tokenize(file_text):\n",
    "    try:\n",
    "        c_file = open('/tmp/test1.c', 'w')\n",
    "        c_file.write(file_text)\n",
    "        c_file.close()\n",
    "        tok = Tokenizer('/tmp/test1.c')\n",
    "        results = tok.split_functions(False)\n",
    "        return ' '.join(results[0])\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65904 953567 65904\n"
     ]
    }
   ],
   "source": [
    "num_vul = 0\n",
    "num_non_vul = 0\n",
    "vul_indices = []\n",
    "\n",
    "for idx, (a, b, c, d, e) in  enumerate(zip(\n",
    "    train_file['CWE-119'], train_file['CWE-120'], train_file['CWE-469'], \n",
    "    train_file['CWE-476'], train_file['CWE-other']\n",
    ")):\n",
    "    if a or b or c or d or e:\n",
    "        num_vul += 1\n",
    "        vul_indices.append(idx)\n",
    "    else:\n",
    "        num_non_vul += 1\n",
    "\n",
    "print(num_vul, num_non_vul, len(vul_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int ID ( ) { int * ID = ID int [ 1 0 ] ; return 5 0 ; }\n",
      "0.06911627604562658\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(\"int main(){\\n\\tint *a = new int[10];\\n\\treturn 50;\\n}\\n\"))\n",
    "ratio = 65907 / float(953567)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "10000 630 9370\n",
      "20000 1310 18690\n",
      "30000 1955 28045\n",
      "40000 2641 37359\n",
      "50000 3245 46755\n",
      "60000 3890 56110\n",
      "70000 4531 65469\n",
      "80000 5142 74858\n",
      "90000 5765 84235\n",
      "100000 6422 93578\n",
      "110000 7074 102926\n",
      "120000 7718 112282\n",
      "130000 8403 121597\n",
      "140000 9048 130952\n",
      "150000 9700 140300\n",
      "160000 10345 149655\n",
      "170000 11001 158999\n",
      "180000 11627 168373\n",
      "190000 12237 177763\n",
      "200000 12866 187134\n",
      "210000 13510 196490\n",
      "220000 14180 205820\n",
      "230000 14836 215164\n",
      "240000 15515 224485\n",
      "250000 16124 233876\n",
      "260000 16785 243215\n",
      "270000 17454 252546\n",
      "280000 18137 261863\n",
      "290000 18781 271219\n",
      "300000 19458 280542\n",
      "310000 20087 289913\n",
      "320000 20733 299267\n",
      "330000 21409 308591\n",
      "340000 22067 317933\n",
      "350000 22749 327251\n",
      "360000 23398 336602\n",
      "370000 24070 345930\n",
      "380000 24698 355302\n",
      "390000 25344 364656\n",
      "400000 25966 374034\n",
      "410000 26581 383419\n",
      "420000 27205 392795\n",
      "430000 27885 402115\n",
      "440000 28529 411471\n",
      "450000 29179 420821\n",
      "460000 29819 430181\n",
      "470000 30467 439533\n",
      "480000 31071 448929\n",
      "490000 31669 458331\n",
      "500000 32327 467673\n",
      "510000 32927 477073\n",
      "520000 33598 486402\n",
      "530000 34229 495771\n",
      "540000 34867 505133\n",
      "550000 35524 514476\n",
      "560000 36175 523825\n",
      "570000 36816 533184\n",
      "580000 37385 542615\n",
      "590000 38033 551967\n",
      "600000 38660 561340\n",
      "610000 39296 570704\n",
      "620000 39959 580041\n",
      "630000 40550 589450\n",
      "640000 41154 598846\n",
      "650000 41773 608227\n",
      "660000 42450 617550\n",
      "670000 43120 626880\n",
      "680000 43831 636169\n",
      "690000 44515 645485\n",
      "700000 45159 654841\n",
      "710000 45800 664200\n",
      "720000 46499 673501\n",
      "730000 47166 682834\n",
      "740000 47831 692169\n",
      "750000 48459 701541\n",
      "760000 49120 710880\n",
      "770000 49773 720227\n",
      "780000 50401 729599\n",
      "790000 51089 738911\n",
      "800000 51731 748269\n",
      "810000 52381 757619\n",
      "820000 53011 766989\n",
      "830000 53653 776347\n",
      "840000 54289 785711\n",
      "850000 54928 795072\n",
      "860000 55583 804417\n",
      "870000 56239 813761\n",
      "880000 56877 823123\n",
      "890000 57544 832456\n",
      "900000 58197 841803\n",
      "910000 58833 851167\n",
      "920000 59465 860535\n",
      "930000 60143 869857\n",
      "940000 60789 879211\n",
      "950000 61445 888555\n",
      "960000 62076 897924\n",
      "970000 62731 907269\n",
      "980000 63321 916679\n",
      "990000 63966 926034\n",
      "1000000 64625 935375\n",
      "1010000 65307 944693\n"
     ]
    }
   ],
   "source": [
    "sources = []\n",
    "v, nv = 0, 0\n",
    "import numpy as np\n",
    "\n",
    "for idx, func in enumerate(train_file['functionSource']):\n",
    "    if idx % 10000 == 0:\n",
    "        print(idx, v, nv)\n",
    "    if idx in vul_indices:\n",
    "        tokenized = tokenize(func.strip())\n",
    "        if tokenize is None:\n",
    "            continue\n",
    "        sources.append({'code': func.strip(), 'label': 1, 'tokenized': tokenized})\n",
    "        v += 1\n",
    "    else:\n",
    "        r = np.random.uniform()\n",
    "        if r <= 1.00:\n",
    "            tokenized = tokenize(func.strip())\n",
    "            if tokenize is None:\n",
    "                continue\n",
    "            sources.append({'code': func.strip(), 'label': 0, 'tokenized': tokenized})\n",
    "            nv += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sources)\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'clear_area(int startx, int starty, int xsize, int ysize)\\n{\\n  int x;\\n\\n  TRACE_LOG(\"Clearing area %d,%d / %d,%d\\\\n\", startx, starty, xsize, ysize);\\n\\n  while (ysize > 0)\\n  {\\n    x = xsize;\\n    while (x > 0)\\n    {\\n      mvaddch(starty + ysize - 2, startx + x - 2, \\' \\');\\n      x--;\\n    }\\n    ysize--;\\n  }\\n}', 'label': 0, 'tokenized': 'ID ( int ID , int ID , int ID , int ID ) { int ID ; ID ( STRING , ID , ID , ID , ID ) ; while ( ID > 0 ) { ID = ID ; while ( ID > 0 ) { ID ( ID + ID - 2 , ID + ID - 2 , LITERAL ) ; ID -- ; } ID -- ; } }'}\n"
     ]
    }
   ],
   "source": [
    "train_file_name = open('../data/draper/train_full.json', 'w')\n",
    "json.dump(sources, train_file_name)\n",
    "train_file_name.close()\n",
    "print(sources[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(file_path):\n",
    "    _file = h5py.File(file_path)\n",
    "    v = 0\n",
    "    nv = 0\n",
    "    sources = []\n",
    "    for idx, (a, b, c, d, e, f) in  enumerate(zip(\n",
    "        _file['CWE-119'], _file['CWE-120'], _file['CWE-469'], \n",
    "        _file['CWE-476'], _file['CWE-other'], _file['functionSource']\n",
    "    )):\n",
    "        if idx % 10000 == 0:\n",
    "            print(idx)\n",
    "        tokenized = tokenize(f)\n",
    "        if tokenized == None:\n",
    "            continue\n",
    "        if a or b or c or d or e:\n",
    "            sources.append({\n",
    "                'code': f.strip(),\n",
    "                'label': 1,\n",
    "                'tokenized': tokenized\n",
    "            })\n",
    "            v += 1\n",
    "        else:\n",
    "            sources.append({\n",
    "                'code': f.strip(),\n",
    "                'label': 0,\n",
    "                'tokenized': tokenized\n",
    "            })\n",
    "            nv += 1\n",
    "    return sources, v, nv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "8109 116583 124692 {'code': 'gwy_resource_class_mkdir(GwyResourceClass *klass)\\n{\\n    gchar *path;\\n    gint ok;\\n\\n    g_return_val_if_fail(GWY_IS_RESOURCE_CLASS(klass), FALSE);\\n\\n    path = g_build_filename(gwy_get_user_dir(), klass->name, NULL);\\n    if (g_file_test(path, G_FILE_TEST_IS_DIR)) {\\n        g_free(path);\\n        return TRUE;\\n    }\\n\\n    ok = !g_mkdir(path, 0700);\\n    g_free(path);\\n\\n    return ok;\\n}', 'label': 0, 'tokenized': 'ID ( ID * ID ) { ID * ID ; ID ID ; ID ( ID ( ID ) , ID ) ; ID = ID ( ID ( ) , ID -> ID , ID ) ; if ( ID ( ID , ID ) ) { ID ( ID ) ; return ID ; } ID = ! ID ( ID , 0 7 0 0 ) ; ID ( ID ) ; return ID ; }'}\n"
     ]
    }
   ],
   "source": [
    "valid_file_name = '../data/draper/VDISC_validate.hdf5'\n",
    "valid_data, v, nv = get_all(valid_file_name)\n",
    "print(v, nv, len(valid_data), valid_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_name = open('../data/draper/valid.json', 'w')\n",
    "\n",
    "json.dump(valid_data, json_file_name)\n",
    "json_file_name.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "8127 116497 124624\n"
     ]
    }
   ],
   "source": [
    "test_file_name = '../data/draper/VDISC_test.hdf5'\n",
    "test_data, v, nv = get_all(test_file_name)\n",
    "print(v, nv, len(test_data))\n",
    "json_file_name = open('../data/draper/test.json', 'w')\n",
    "\n",
    "json.dump(test_data, json_file_name)\n",
    "json_file_name.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
